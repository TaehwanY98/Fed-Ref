{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.CustomDataset import OCTDL\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seeding(num):\n",
    "    torch.manual_seed(num)\n",
    "    torch.cuda.manual_seed(num)\n",
    "    torch.cuda.manual_seed_all(num)\n",
    "    np.random.seed(num)\n",
    "    random.seed(num)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "seeding(2025)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def evaluation(net, loader, f1, f2, f3, DEVICE):\n",
    "    net.eval()\n",
    "    net.to(DEVICE)\n",
    "    accf= f1.to(DEVICE)\n",
    "    f1scoref = f2.to(DEVICE)\n",
    "    rmsef = f3.to(DEVICE)\n",
    "    acc = 0\n",
    "    f1score = 0\n",
    "    rmse = 0\n",
    "    length = len(loader)\n",
    "    for sample in loader:\n",
    "        X= torch.stack([s[\"x\"] for s in sample], 0)\n",
    "        Y= torch.stack([s[\"y\"] for s in sample], 0)\n",
    "        out = net(X.type(torch.float32).to(DEVICE)) \n",
    "        acc += accf(out.type(torch.float32).to(DEVICE), torch.nn.functional.one_hot(Y.type(torch.int64), 7).squeeze().to(DEVICE)).item()\n",
    "        f1score += f1scoref(out.type(torch.float32).to(DEVICE), torch.nn.functional.one_hot(Y.type(torch.int64), 7).squeeze().to(DEVICE)).item()\n",
    "        rmse += torch.sqrt(rmsef(out.type(torch.float32).to(DEVICE), torch.nn.functional.one_hot(Y.type(torch.int64), 7).squeeze().type(torch.float32).to(DEVICE))).item()\n",
    "    return {\"acc\": acc/length, \"f1score\":f1score/length, 'rmse': rmse/length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from Network.Resnet import ResNet\n",
    "\n",
    "testset = OCTDL(\"Data/OCTDL/clients/test\")\n",
    "testloader = DataLoader(testset, 16, False, collate_fn= lambda x: x)\n",
    "net = ResNet().to(DEVICE)\n",
    "net.load_state_dict(torch.load(\"Models/CentralOCT/net.pt\"))\n",
    "\n",
    "evaluation(net, testloader, Accuracy(\"multiclass\", num_classes=7, average=\"macro\"), F1Score(\"multiclass\", num_classes=7, average=\"macro\"),\n",
    "            MeanSquaredError(), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from Network.Resnet import ResNet\n",
    "\n",
    "testset = OCTDL(\"Data/OCTDL/clients/test\")\n",
    "testloader = DataLoader(testset, 16, False, collate_fn= lambda x: x)\n",
    "net = ResNet().to(DEVICE)\n",
    "net.load_state_dict(torch.load(\"Models/FedAvgOCT/net.pt\"))\n",
    "\n",
    "evaluation(net, testloader, Accuracy(\"multiclass\", num_classes=7, average=\"macro\"), F1Score(\"multiclass\", num_classes=7, average=\"macro\"),\n",
    "            MeanSquaredError(), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from Network.Resnet import ResNet\n",
    "\n",
    "testset = OCTDL(\"Data/OCTDL/clients/test\")\n",
    "testloader = DataLoader(testset, 16, False, collate_fn= lambda x: x)\n",
    "net = ResNet().to(DEVICE)\n",
    "net.load_state_dict(torch.load(\"Models/FedPIDOCT/net.pt\"))\n",
    "\n",
    "evaluation(net, testloader, Accuracy(\"multiclass\", num_classes=7, average=\"macro\"), F1Score(\"multiclass\", num_classes=7, average=\"macro\"),\n",
    "            MeanSquaredError(), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from Network.Resnet import ResNet\n",
    "\n",
    "testset = OCTDL(\"Data/OCTDL/clients/test\")\n",
    "testloader = DataLoader(testset, 16, False, collate_fn= lambda x: x)\n",
    "net = ResNet().to(DEVICE)\n",
    "net.load_state_dict(torch.load(\"Models/FedLWROCT/net.pt\"))\n",
    "\n",
    "evaluation(net, testloader, Accuracy(\"multiclass\", num_classes=7, average=\"macro\"), F1Score(\"multiclass\", num_classes=7, average=\"macro\"),\n",
    "            MeanSquaredError(), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from Network.Resnet import ResNet\n",
    "\n",
    "testset = OCTDL(\"Data/OCTDL/clients/test\")\n",
    "testloader = DataLoader(testset, 16, False, collate_fn= lambda x: x)\n",
    "net = ResNet().to(DEVICE)\n",
    "net.load_state_dict(torch.load(\"Models/FedRefOCT/net.pt\"))\n",
    "\n",
    "evaluation(net, testloader, Accuracy(\"multiclass\", num_classes=7, average=\"macro\"), F1Score(\"multiclass\", num_classes=7, average=\"macro\"),\n",
    "            MeanSquaredError(), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# fedavgframe = pd.read_csv('Result/FedAvg_loss_OCTDL.csv')\n",
    "# fedpidframe = pd.read_csv('Result/FedPID_loss_OCTDL.csv')\n",
    "# fedlwrframe = pd.read_csv('Result/FedLWR_loss_OCTDL.csv')\n",
    "# fedrefframe = pd.read_csv(\"Result/FedRef_loss_OCTDL.csv\")\n",
    "# plt.plot(fedavgframe['1'].to_numpy(), color=(0.5,0,1), label= \"Fed-Avg\", marker= \".\")\n",
    "# plt.plot(fedlwrframe['1'].to_numpy(), color=(0.5,1,0.9), label= \"Fed-LWR\", marker= \".\")\n",
    "# plt.plot(fedpidframe['1'].to_numpy(), color=(0.5,1,0), label= \"Fed-PID\", marker= \".\")\n",
    "# plt.plot(fedrefframe['1'].to_numpy(), color=(1,0,0), label= \"Fed-Ref\", marker= \".\")\n",
    "# plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# fedavgframe = pd.read_csv('Result/FedAvg_OCTDL.csv')\n",
    "# fedpidframe = pd.read_csv('Result/FedPID_OCTDL.csv')\n",
    "# fedlwrframe = pd.read_csv('Result/FedLWR_OCTDL.csv')\n",
    "# fedrefframe = pd.read_csv(\"Result/FedRef_OCTDL.csv\")\n",
    "# plt.plot(fedavgframe['accuracy'].to_numpy(), color=(0.5,0,1), label= \"Fed-Avg\", marker= \".\")\n",
    "# plt.plot(fedlwrframe['accuracy'].to_numpy(), color=(0.5,1,0.9), label= \"Fed-LWR\", marker= \".\")\n",
    "# plt.plot(fedpidframe['accuracy'].to_numpy(), color=(0.5,1,0), label= \"Fed-PID\", marker= \".\")\n",
    "# plt.plot(fedrefframe['accuracy'].to_numpy(), color=(1,0,0), label= \"Fed-Ref\", marker= \".\")\n",
    "# plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# fedavgframe = pd.read_csv('Result/FedAvg_OCTDL.csv')\n",
    "# fedpidframe = pd.read_csv('Result/FedPID_OCTDL.csv')\n",
    "# fedlwrframe = pd.read_csv('Result/FedLWR_OCTDL.csv')\n",
    "# fedrefframe = pd.read_csv(\"Result/FedRef_OCTDL.csv\")\n",
    "# plt.plot(fedavgframe['f1score'].to_numpy(), color=(0.5,0,1), label= \"Fed-Avg\", marker= \".\")\n",
    "# plt.plot(fedlwrframe['f1score'].to_numpy(), color=(0.5,1,0.9), label= \"Fed-LWR\", marker= \".\")\n",
    "# plt.plot(fedpidframe['f1score'].to_numpy(), color=(0.5,1,0), label= \"Fed-PID\", marker= \".\")\n",
    "# plt.plot(fedrefframe['f1score'].to_numpy(), color=(1,0,0), label= \"Fed-Ref\", marker= \".\")\n",
    "# plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO', 'AMD', 'DME', 'ERM', 'RAO', 'RVO', 'VID']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8177, 0.4323, 0.8958, 0.9167, 0.9896, 0.9688, 0.9792])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.CustomDataset import OCTDL\n",
    "test=OCTDL(\"Data/OCTDL/clients/1\")\n",
    "print(test.patients)\n",
    "test.label_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
